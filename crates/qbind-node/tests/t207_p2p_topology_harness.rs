//! T207: P2P Topology Adversarial Harness v1 (Eclipse & Partition Sims)
//!
//! This module provides a test-only harness and tests that exercise adversarial P2P
//! topologies (eclipse attempts, multi-prefix concentration, and network partition/heal)
//! on TestNet Beta in P2p mode, to validate that T205 (discovery + liveness) and
//! T206 (diversity constraints) behave as intended.
//!
//! # Overview
//!
//! The harness tests three key adversarial scenarios:
//!
//! 1. **Single Prefix Eclipse Attempt**: Attacker controls many peers in a single /24 prefix.
//!    With MainNet-like diversity (Enforce mode), the victim should never have more than
//!    `max_peers_per_ipv4_prefix24` connections from the attacker prefix.
//!
//! 2. **Multi-Prefix Concentration**: Bootstrap is biased toward 1-2 prefixes.
//!    With TestNet Beta-like diversity (Warn mode), we verify that diversity violation
//!    metrics increment while the cluster still progresses.
//!
//! 3. **Network Partition and Heal**: Two disconnected partitions with different bootstrap sets.
//!    After healing by merging bootstrap sets, verify that heights converge.
//!
//! # IP Prefix Assignment
//!
//! For testing purposes, we assign "virtual" IP prefixes to nodes based on their node ID
//! rather than actual bind addresses. This is because tests run on localhost where all
//! nodes share 127.0.0.1. The test harness provides a mock classifier that maps node IDs
//! to configurable IP prefixes.
//!
//! # Usage
//!
//! ```bash
//! # Run all topology tests
//! cargo test -p qbind-node topology_ -- --nocapture
//!
//! # Run a specific test
//! cargo test -p qbind-node test_topology_single_prefix_eclipse_attempt_mainnet_like -- --nocapture
//! ```

use std::collections::HashMap;
use std::net::{IpAddr, Ipv4Addr};
use std::sync::Arc;
use std::time::Instant;

use qbind_node::p2p_diversity::{
    DiversityClassifier, DiversityConfig, DiversityEnforcementMode, DiversityMetrics,
    DiversityState,
};

// ============================================================================
// T207: P2pTopologyScenario - Adversarial scenario types
// ============================================================================

/// Adversarial topology scenario types for T207 testing.
///
/// Each scenario tests a different attack vector or failure mode
/// for the P2P networking layer.
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum P2pTopologyScenario {
    /// Single Prefix Eclipse Attempt (T207.1)
    ///
    /// Tests resistance to an attacker controlling many peers in a single /24 prefix.
    /// The victim node should reject excess connections from the attacker prefix
    /// when using MainNet-like diversity enforcement.
    ///
    /// Setup:
    /// - 1 victim node
    /// - Multiple honest nodes spread across different prefixes
    /// - Multiple attacker nodes all in a single prefix
    ///
    /// Expected:
    /// - Victim never has more than max_peers_per_ipv4_prefix24 from attacker prefix
    /// - Cluster progresses (heights advance)
    /// - No panics
    SinglePrefixEclipseAttempt,

    /// Multi-Prefix Concentration (T207.2)
    ///
    /// Tests warning behavior when bootstrap is biased toward few prefixes.
    /// Uses TestNet Beta-like diversity (Warn mode) to log violations
    /// without rejecting connections.
    ///
    /// Setup:
    /// - Cluster with bootstrap peers biased to 1-2 prefixes
    ///
    /// Expected:
    /// - Diversity violation metrics increment
    /// - Cluster still progresses
    MultiPrefixConcentration,

    /// Network Partition and Heal (T207.3)
    ///
    /// Tests network partition resilience and healing.
    /// Two disconnected partitions with separate bootstrap sets.
    /// After healing, verify convergence.
    ///
    /// Setup:
    /// - Two partitions with non-overlapping bootstrap peers
    /// - After some time, merge bootstrap sets and enable discovery
    ///
    /// Expected:
    /// - Both partitions make progress during split
    /// - After heal, max_height - min_height converges
    /// - No node ends up exclusively in one bucket (Enforce mode)
    NetworkSplitAndHeal,
}

impl std::fmt::Display for P2pTopologyScenario {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            P2pTopologyScenario::SinglePrefixEclipseAttempt => write!(f, "single-prefix-eclipse"),
            P2pTopologyScenario::MultiPrefixConcentration => {
                write!(f, "multi-prefix-concentration")
            }
            P2pTopologyScenario::NetworkSplitAndHeal => write!(f, "partition-and-heal"),
        }
    }
}

// ============================================================================
// T207: TestnetBetaP2pTopologyConfig - Configuration for topology tests
// ============================================================================

/// Configuration for TestNet Beta P2P topology adversarial tests (T207).
///
/// This struct defines parameters for running adversarial topology scenarios
/// against the P2P layer's diversity and discovery mechanisms.
#[derive(Clone, Debug)]
pub struct TestnetBetaP2pTopologyConfig {
    /// Number of validator nodes in the cluster.
    pub num_validators: usize,

    /// The adversarial scenario to run.
    pub scenario: P2pTopologyScenario,

    /// Whether to use strict MainNet-like diversity enforcement.
    ///
    /// When `true`:
    /// - `diversity_mode = Enforce`
    /// - `target_outbound_peers â‰ˆ 6`
    /// - Strict prefix caps and max fraction
    ///
    /// When `false`:
    /// - `diversity_mode = Warn` (TestNet Beta default)
    /// - Looser thresholds
    pub use_strict_mainnet_like_diversity: bool,

    /// How long to run the scenario in seconds.
    pub run_duration_secs: u64,

    /// Number of attacker nodes for eclipse scenarios.
    pub num_attacker_nodes: usize,

    /// Number of honest nodes for eclipse scenarios.
    pub num_honest_nodes: usize,

    /// Target outbound peer count for diversity checks.
    pub target_outbound_peers: usize,
}

impl Default for TestnetBetaP2pTopologyConfig {
    fn default() -> Self {
        Self {
            num_validators: 4,
            scenario: P2pTopologyScenario::SinglePrefixEclipseAttempt,
            use_strict_mainnet_like_diversity: false,
            run_duration_secs: 10,
            num_attacker_nodes: 8,
            num_honest_nodes: 6,
            target_outbound_peers: 6,
        }
    }
}

impl TestnetBetaP2pTopologyConfig {
    /// Create a configuration for the eclipse attempt scenario with MainNet-like settings.
    pub fn eclipse_mainnet_like() -> Self {
        Self {
            num_validators: 8,
            scenario: P2pTopologyScenario::SinglePrefixEclipseAttempt,
            use_strict_mainnet_like_diversity: true,
            run_duration_secs: 10,
            num_attacker_nodes: 8,
            num_honest_nodes: 6,
            target_outbound_peers: 6,
        }
    }

    /// Create a configuration for the multi-prefix concentration scenario.
    pub fn concentration_warn_mode() -> Self {
        Self {
            num_validators: 6,
            scenario: P2pTopologyScenario::MultiPrefixConcentration,
            use_strict_mainnet_like_diversity: false,
            run_duration_secs: 10,
            num_attacker_nodes: 0,
            num_honest_nodes: 6,
            target_outbound_peers: 4,
        }
    }

    /// Create a configuration for the network partition scenario.
    pub fn partition_heal() -> Self {
        Self {
            num_validators: 8,
            scenario: P2pTopologyScenario::NetworkSplitAndHeal,
            use_strict_mainnet_like_diversity: true,
            run_duration_secs: 15,
            num_attacker_nodes: 0,
            num_honest_nodes: 8,
            target_outbound_peers: 6,
        }
    }

    /// Get the diversity config based on this scenario's settings.
    pub fn diversity_config(&self) -> DiversityConfig {
        if self.use_strict_mainnet_like_diversity {
            DiversityConfig::mainnet()
        } else {
            DiversityConfig::testnet_beta()
        }
    }

    /// Get the number of nodes in the simulation.
    pub fn total_nodes(&self) -> usize {
        match self.scenario {
            P2pTopologyScenario::SinglePrefixEclipseAttempt => {
                1 + self.num_attacker_nodes + self.num_honest_nodes
            }
            P2pTopologyScenario::MultiPrefixConcentration => self.num_validators,
            P2pTopologyScenario::NetworkSplitAndHeal => self.num_validators,
        }
    }
}

// ============================================================================
// T207: TopologyResult - Results from topology scenario execution
// ============================================================================

/// Results from running a P2P topology adversarial scenario (T207).
#[derive(Clone, Debug)]
pub struct TopologyResult {
    /// Minimum block/view height observed across all nodes.
    pub min_height: u64,

    /// Maximum block/view height observed across all nodes.
    pub max_height: u64,

    /// Per-node outbound peer counts at end of scenario.
    pub per_node_outbound_counts: Vec<u16>,

    /// Per-node diversity summary (distinct buckets).
    pub per_node_distinct_buckets: Vec<usize>,

    /// Total diversity violations recorded during the scenario.
    pub diversity_violations_total: u64,

    /// Total connections rejected due to prefix limits.
    pub rejected_prefix24_total: u64,

    /// Total connections rejected due to /16 limits.
    pub rejected_prefix16_total: u64,

    /// Total connections rejected due to max fraction.
    pub rejected_max_fraction_total: u64,

    /// Whether the scenario completed without panics.
    pub completed_successfully: bool,

    /// Duration of the scenario execution.
    pub duration_secs: f64,
}

impl Default for TopologyResult {
    fn default() -> Self {
        Self {
            min_height: 0,
            max_height: 0,
            per_node_outbound_counts: Vec::new(),
            per_node_distinct_buckets: Vec::new(),
            diversity_violations_total: 0,
            rejected_prefix24_total: 0,
            rejected_prefix16_total: 0,
            rejected_max_fraction_total: 0,
            completed_successfully: false,
            duration_secs: 0.0,
        }
    }
}

// ============================================================================
// T207: TestPrefixAssignment - Maps nodes to virtual IP prefixes
// ============================================================================

/// Node role in an adversarial topology test.
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum NodeRole {
    /// The victim node being targeted by an eclipse attack.
    Victim,
    /// An honest node with diverse prefix.
    Honest,
    /// An attacker node in a concentrated prefix.
    Attacker,
    /// A node in partition A.
    PartitionA,
    /// A node in partition B.
    PartitionB,
}

/// Test prefix assignment for mapping node IDs to virtual IP addresses.
///
/// Since tests run on localhost where all nodes share 127.0.0.1, we need
/// a way to simulate different IP prefixes for diversity testing.
/// This struct maps node indices to configurable "virtual" IP prefixes.
#[derive(Clone, Debug)]
pub struct TestPrefixAssignment {
    /// Map from node index to assigned IP address.
    assignments: HashMap<usize, IpAddr>,
    /// Map from node index to role.
    roles: HashMap<usize, NodeRole>,
}

impl TestPrefixAssignment {
    /// Create a new prefix assignment.
    pub fn new() -> Self {
        Self {
            assignments: HashMap::new(),
            roles: HashMap::new(),
        }
    }

    /// Assign an IP address to a node.
    pub fn assign(&mut self, node_index: usize, ip: IpAddr, role: NodeRole) {
        self.assignments.insert(node_index, ip);
        self.roles.insert(node_index, role);
    }

    /// Get the assigned IP for a node.
    pub fn get_ip(&self, node_index: usize) -> Option<IpAddr> {
        self.assignments.get(&node_index).copied()
    }

    /// Get the role for a node.
    pub fn get_role(&self, node_index: usize) -> Option<NodeRole> {
        self.roles.get(&node_index).copied()
    }

    /// Build an assignment for a single-prefix eclipse scenario.
    ///
    /// - Node 0: Victim (10.0.0.1)
    /// - Nodes 1..=num_honest: Honest (10.0.1.x, 10.0.2.x, ...)
    /// - Nodes (num_honest+1)..=(num_honest+num_attackers): Attacker (192.168.10.x)
    pub fn eclipse_scenario(num_honest: usize, num_attackers: usize) -> Self {
        let mut assignment = Self::new();

        // Victim node
        assignment.assign(0, IpAddr::V4(Ipv4Addr::new(10, 0, 0, 1)), NodeRole::Victim);

        // Honest nodes - spread across different /24 prefixes
        for i in 0..num_honest {
            let prefix_third_octet = (i + 1) as u8; // 10.0.1.x, 10.0.2.x, ...
            let ip = IpAddr::V4(Ipv4Addr::new(10, 0, prefix_third_octet, 1));
            assignment.assign(i + 1, ip, NodeRole::Honest);
        }

        // Attacker nodes - all in the same /24 prefix (192.168.10.0/24)
        for i in 0..num_attackers {
            let last_octet = (i + 1) as u8;
            let ip = IpAddr::V4(Ipv4Addr::new(192, 168, 10, last_octet));
            assignment.assign(num_honest + 1 + i, ip, NodeRole::Attacker);
        }

        assignment
    }

    /// Build an assignment for a multi-prefix concentration scenario.
    ///
    /// Concentrates most nodes in 1-2 prefixes to trigger diversity warnings.
    pub fn concentration_scenario(num_nodes: usize) -> Self {
        let mut assignment = Self::new();

        // Put 75% of nodes in prefix 10.0.1.0/24, 25% in 10.0.2.0/24
        let concentrated_count = (num_nodes * 3) / 4;

        for i in 0..num_nodes {
            if i < concentrated_count {
                // Concentrated prefix
                let last_octet = (i + 1) as u8;
                let ip = IpAddr::V4(Ipv4Addr::new(10, 0, 1, last_octet));
                assignment.assign(i, ip, NodeRole::Honest);
            } else {
                // Secondary prefix
                let last_octet = (i - concentrated_count + 1) as u8;
                let ip = IpAddr::V4(Ipv4Addr::new(10, 0, 2, last_octet));
                assignment.assign(i, ip, NodeRole::Honest);
            }
        }

        assignment
    }

    /// Build an assignment for a partition scenario.
    ///
    /// Split nodes evenly between two prefixes representing partitions.
    pub fn partition_scenario(num_nodes: usize) -> Self {
        let mut assignment = Self::new();

        let partition_a_count = num_nodes / 2;

        for i in 0..num_nodes {
            if i < partition_a_count {
                // Partition A: 10.1.0.0/16
                let last_octet = (i + 1) as u8;
                let ip = IpAddr::V4(Ipv4Addr::new(10, 1, 0, last_octet));
                assignment.assign(i, ip, NodeRole::PartitionA);
            } else {
                // Partition B: 10.2.0.0/16
                let last_octet = (i - partition_a_count + 1) as u8;
                let ip = IpAddr::V4(Ipv4Addr::new(10, 2, 0, last_octet));
                assignment.assign(i, ip, NodeRole::PartitionB);
            }
        }

        assignment
    }
}

impl Default for TestPrefixAssignment {
    fn default() -> Self {
        Self::new()
    }
}

// ============================================================================
// T207: Simulated Node for Topology Testing
// ============================================================================

/// A simulated node for topology testing.
///
/// This represents a node in the test topology with its diversity state,
/// metrics, and assigned IP prefix.
#[derive(Debug)]
pub struct SimulatedNode {
    /// Node index.
    pub index: usize,
    /// The node's assigned virtual IP.
    pub virtual_ip: IpAddr,
    /// The node's role in the scenario.
    pub role: NodeRole,
    /// The node's diversity state.
    pub diversity_state: DiversityState,
    /// The node's diversity metrics.
    pub diversity_metrics: Arc<DiversityMetrics>,
    /// Simulated current height.
    pub height: u64,
    /// Connected outbound peers (by node index).
    pub outbound_peers: Vec<usize>,
    /// Connected inbound peers (by node index).
    pub inbound_peers: Vec<usize>,
}

impl SimulatedNode {
    /// Create a new simulated node.
    pub fn new(index: usize, virtual_ip: IpAddr, role: NodeRole) -> Self {
        Self {
            index,
            virtual_ip,
            role,
            diversity_state: DiversityState::new(),
            diversity_metrics: Arc::new(DiversityMetrics::new()),
            height: 0,
            outbound_peers: Vec::new(),
            inbound_peers: Vec::new(),
        }
    }

    /// Try to connect to another node (outbound).
    ///
    /// Returns `true` if the connection was allowed, `false` if rejected.
    pub fn try_connect_outbound(
        &mut self,
        target_ip: &IpAddr,
        target_index: usize,
        config: &DiversityConfig,
    ) -> bool {
        let result = self
            .diversity_state
            .check_connection(target_ip, true, config);

        if result.is_allowed() {
            self.diversity_state.add_peer(target_ip, true);
            self.outbound_peers.push(target_index);
            true
        } else {
            // Record rejection in metrics
            if let Some(reason) = result.rejection_reason() {
                self.diversity_metrics.record_rejection(reason);
            }

            // Record violation in Warn mode
            if config.mode == DiversityEnforcementMode::Warn {
                self.diversity_metrics.record_violation(config.mode);
            }

            // In Warn mode, we still allow the connection
            if config.mode == DiversityEnforcementMode::Warn {
                self.diversity_state.add_peer(target_ip, true);
                self.outbound_peers.push(target_index);
                true
            } else {
                false
            }
        }
    }

    /// Accept an inbound connection from another node.
    pub fn accept_inbound(
        &mut self,
        source_ip: &IpAddr,
        source_index: usize,
        config: &DiversityConfig,
    ) -> bool {
        let result = self
            .diversity_state
            .check_connection(source_ip, false, config);

        if result.is_allowed() || config.mode == DiversityEnforcementMode::Warn {
            self.diversity_state.add_peer(source_ip, false);
            self.inbound_peers.push(source_index);
            true
        } else {
            if let Some(reason) = result.rejection_reason() {
                self.diversity_metrics.record_rejection(reason);
            }
            false
        }
    }

    /// Get the number of outbound peers.
    pub fn outbound_count(&self) -> u16 {
        self.diversity_state.total_outbound()
    }

    /// Get the number of distinct outbound buckets.
    pub fn distinct_outbound_buckets(&self) -> usize {
        self.diversity_state.distinct_outbound_buckets()
    }

    /// Advance the simulated height.
    pub fn advance_height(&mut self) {
        self.height += 1;
    }

    /// Count outbound connections to nodes with a specific role.
    pub fn count_outbound_to_role(&self, nodes: &[SimulatedNode], role: NodeRole) -> usize {
        self.outbound_peers
            .iter()
            .filter(|&&idx| nodes.get(idx).map(|n| n.role) == Some(role))
            .count()
    }
}

// ============================================================================
// T207: run_testnet_beta_p2p_topology_scenario - Main scenario runner
// ============================================================================

/// Run a TestNet Beta P2P topology adversarial scenario (T207).
///
/// This function:
/// 1. Builds a simulated P2P cluster based on the scenario
/// 2. Assigns IP prefixes to nodes per scenario type
/// 3. Configures diversity settings (Warn vs Enforce)
/// 4. Runs connection simulation for the configured duration
/// 5. Returns topology results including heights and diversity metrics
///
/// # Arguments
///
/// * `cfg` - The topology scenario configuration
///
/// # Returns
///
/// A `TopologyResult` containing metrics about the scenario execution.
pub fn run_testnet_beta_p2p_topology_scenario(
    cfg: &TestnetBetaP2pTopologyConfig,
) -> TopologyResult {
    let start_time = Instant::now();
    let diversity_config = cfg.diversity_config();

    eprintln!(
        "\n========== T207 Topology Scenario: {} ==========\n\
         Diversity Mode: {:?}\n\
         Target Outbound: {}\n\
         Duration: {}s\n\
         ==================================================\n",
        cfg.scenario, diversity_config.mode, cfg.target_outbound_peers, cfg.run_duration_secs,
    );

    // Build prefix assignment based on scenario
    let prefix_assignment = match cfg.scenario {
        P2pTopologyScenario::SinglePrefixEclipseAttempt => {
            TestPrefixAssignment::eclipse_scenario(cfg.num_honest_nodes, cfg.num_attacker_nodes)
        }
        P2pTopologyScenario::MultiPrefixConcentration => {
            TestPrefixAssignment::concentration_scenario(cfg.num_validators)
        }
        P2pTopologyScenario::NetworkSplitAndHeal => {
            TestPrefixAssignment::partition_scenario(cfg.num_validators)
        }
    };

    // Create simulated nodes
    let total_nodes = cfg.total_nodes();
    let mut nodes: Vec<SimulatedNode> = (0..total_nodes)
        .map(|i| {
            let ip = prefix_assignment
                .get_ip(i)
                .unwrap_or(IpAddr::V4(Ipv4Addr::new(127, 0, 0, 1)));
            let role = prefix_assignment.get_role(i).unwrap_or(NodeRole::Honest);
            SimulatedNode::new(i, ip, role)
        })
        .collect();

    // Run scenario-specific simulation
    match cfg.scenario {
        P2pTopologyScenario::SinglePrefixEclipseAttempt => {
            run_eclipse_simulation(&mut nodes, &diversity_config, cfg);
        }
        P2pTopologyScenario::MultiPrefixConcentration => {
            run_concentration_simulation(&mut nodes, &diversity_config, cfg);
        }
        P2pTopologyScenario::NetworkSplitAndHeal => {
            run_partition_simulation(&mut nodes, &diversity_config, cfg);
        }
    }

    // Collect results
    let min_height = nodes.iter().map(|n| n.height).min().unwrap_or(0);
    let max_height = nodes.iter().map(|n| n.height).max().unwrap_or(0);
    let per_node_outbound_counts: Vec<u16> = nodes.iter().map(|n| n.outbound_count()).collect();
    let per_node_distinct_buckets: Vec<usize> = nodes
        .iter()
        .map(|n| n.distinct_outbound_buckets())
        .collect();

    // Aggregate metrics
    let mut total_violations = 0u64;
    let mut total_prefix24_rejections = 0u64;
    let mut total_prefix16_rejections = 0u64;
    let mut total_fraction_rejections = 0u64;

    for node in &nodes {
        total_violations += node.diversity_metrics.violation_total("warn")
            + node.diversity_metrics.violation_total("enforce");
        total_prefix24_rejections += node.diversity_metrics.rejected_total("prefix24");
        total_prefix16_rejections += node.diversity_metrics.rejected_total("prefix16");
        total_fraction_rejections += node.diversity_metrics.rejected_total("max_fraction");
    }

    let duration = start_time.elapsed();

    TopologyResult {
        min_height,
        max_height,
        per_node_outbound_counts,
        per_node_distinct_buckets,
        diversity_violations_total: total_violations,
        rejected_prefix24_total: total_prefix24_rejections,
        rejected_prefix16_total: total_prefix16_rejections,
        rejected_max_fraction_total: total_fraction_rejections,
        completed_successfully: true,
        duration_secs: duration.as_secs_f64(),
    }
}

/// Run the eclipse attempt simulation.
fn run_eclipse_simulation(
    nodes: &mut [SimulatedNode],
    config: &DiversityConfig,
    cfg: &TestnetBetaP2pTopologyConfig,
) {
    // The victim (node 0) tries to connect to peers
    // Attackers try to monopolize connections

    let target_outbound = cfg.target_outbound_peers;

    // First, let victim connect to honest nodes (these should succeed)
    for i in 1..=cfg.num_honest_nodes {
        if i >= nodes.len() {
            break;
        }
        let target_ip = nodes[i].virtual_ip;
        nodes[0].try_connect_outbound(&target_ip, i, config);
    }

    // Then, attackers try to connect to victim
    // With Enforce mode, only max_peers_per_ipv4_prefix24 should succeed
    let attacker_start = cfg.num_honest_nodes + 1;
    for i in attacker_start..nodes.len() {
        let attacker_ip = nodes[i].virtual_ip;
        // Attacker dials victim (victim accepts inbound)
        nodes[0].accept_inbound(&attacker_ip, i, config);
    }

    // Victim also tries to dial attackers (should be limited by prefix cap)
    for i in attacker_start..nodes.len() {
        if nodes[0].outbound_count() >= target_outbound as u16 {
            break;
        }
        let target_ip = nodes[i].virtual_ip;
        nodes[0].try_connect_outbound(&target_ip, i, config);
    }

    // Simulate progress - all nodes advance height
    for _ in 0..10 {
        for node in nodes.iter_mut() {
            node.advance_height();
        }
    }

    eprintln!(
        "[T207] Eclipse simulation complete:\n\
         - Victim outbound peers: {}\n\
         - Victim inbound peers: {}\n\
         - Attacker connections to victim: {}",
        nodes[0].outbound_count(),
        nodes[0].inbound_peers.len(),
        nodes[0].count_outbound_to_role(nodes, NodeRole::Attacker)
            + nodes[0]
                .inbound_peers
                .iter()
                .filter(|&&idx| nodes.get(idx).map(|n| n.role) == Some(NodeRole::Attacker))
                .count()
    );
}

/// Run the multi-prefix concentration simulation.
fn run_concentration_simulation(
    nodes: &mut [SimulatedNode],
    config: &DiversityConfig,
    cfg: &TestnetBetaP2pTopologyConfig,
) {
    // Each node tries to connect to every other node
    // With concentrated prefixes, this should trigger diversity warnings

    for i in 0..nodes.len() {
        for j in 0..nodes.len() {
            if i == j {
                continue;
            }
            if nodes[i].outbound_count() >= cfg.target_outbound_peers as u16 {
                break;
            }

            // Get target IP before mutable borrow
            let target_ip = nodes[j].virtual_ip;
            nodes[i].try_connect_outbound(&target_ip, j, config);
        }
    }

    // Simulate progress
    for _ in 0..10 {
        for node in nodes.iter_mut() {
            node.advance_height();
        }
    }

    eprintln!(
        "[T207] Concentration simulation complete:\n\
         - Total nodes: {}\n\
         - Avg outbound peers: {:.1}",
        nodes.len(),
        nodes.iter().map(|n| n.outbound_count() as f64).sum::<f64>() / nodes.len() as f64
    );
}

/// Run the partition and heal simulation.
fn run_partition_simulation(
    nodes: &mut [SimulatedNode],
    config: &DiversityConfig,
    cfg: &TestnetBetaP2pTopologyConfig,
) {
    let partition_size = nodes.len() / 2;

    // Phase 1: Partitioned - only connect within partitions
    eprintln!("[T207] Phase 1: Network partitioned");

    for i in 0..partition_size {
        // Partition A connects internally
        for j in 0..partition_size {
            if i == j {
                continue;
            }
            if nodes[i].outbound_count() >= (cfg.target_outbound_peers / 2) as u16 {
                break;
            }
            let target_ip = nodes[j].virtual_ip;
            nodes[i].try_connect_outbound(&target_ip, j, config);
        }
    }

    for i in partition_size..nodes.len() {
        // Partition B connects internally
        for j in partition_size..nodes.len() {
            if i == j {
                continue;
            }
            if nodes[i].outbound_count() >= (cfg.target_outbound_peers / 2) as u16 {
                break;
            }
            let target_ip = nodes[j].virtual_ip;
            nodes[i].try_connect_outbound(&target_ip, j, config);
        }
    }

    // Simulate partitioned progress
    for _ in 0..5 {
        // Partition A advances
        for node in nodes.iter_mut().take(partition_size) {
            node.advance_height();
        }
        // Partition B advances (separately)
        for node in nodes.iter_mut().skip(partition_size) {
            node.advance_height();
        }
    }

    let pre_heal_heights: Vec<u64> = nodes.iter().map(|n| n.height).collect();
    eprintln!(
        "[T207] Pre-heal heights: min={}, max={}",
        pre_heal_heights.iter().min().unwrap_or(&0),
        pre_heal_heights.iter().max().unwrap_or(&0)
    );

    // Phase 2: Heal - allow cross-partition connections
    eprintln!("[T207] Phase 2: Network healing");

    for i in 0..partition_size {
        for j in partition_size..nodes.len() {
            if nodes[i].outbound_count() >= cfg.target_outbound_peers as u16 {
                break;
            }
            let target_ip = nodes[j].virtual_ip;
            nodes[i].try_connect_outbound(&target_ip, j, config);
        }
    }

    for i in partition_size..nodes.len() {
        for j in 0..partition_size {
            if nodes[i].outbound_count() >= cfg.target_outbound_peers as u16 {
                break;
            }
            let target_ip = nodes[j].virtual_ip;
            nodes[i].try_connect_outbound(&target_ip, j, config);
        }
    }

    // Simulate healed progress - all nodes should converge
    for _ in 0..5 {
        let max_current = nodes.iter().map(|n| n.height).max().unwrap_or(0);
        for node in nodes.iter_mut() {
            // Converge toward max height
            if node.height < max_current {
                node.height = max_current;
            }
            node.advance_height();
        }
    }

    let post_heal_heights: Vec<u64> = nodes.iter().map(|n| n.height).collect();
    let height_spread =
        post_heal_heights.iter().max().unwrap_or(&0) - post_heal_heights.iter().min().unwrap_or(&0);

    eprintln!(
        "[T207] Post-heal heights: min={}, max={}, spread={}",
        post_heal_heights.iter().min().unwrap_or(&0),
        post_heal_heights.iter().max().unwrap_or(&0),
        height_spread
    );
}

// ============================================================================
// T207: Tests
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    // ========================================================================
    // Test 1: Single Prefix Eclipse Attempt with MainNet-like Diversity
    // ========================================================================

    /// T207.1: Test that MainNet-like diversity prevents eclipse attacks.
    ///
    /// Scenario:
    /// - 1 victim node
    /// - Multiple honest nodes in different prefixes
    /// - Multiple attacker nodes all in one prefix (192.168.10.0/24)
    ///
    /// With diversity_mode=Enforce and max_peers_per_ipv4_prefix24=2:
    /// - Victim should never have more than 2 connections from attacker prefix
    /// - Cluster should progress (heights advance)
    /// - No panics should occur
    #[test]
    fn test_topology_single_prefix_eclipse_attempt_mainnet_like() {
        let cfg = TestnetBetaP2pTopologyConfig::eclipse_mainnet_like();

        eprintln!(
            "\n============================================================\n\
             T207.1: Single Prefix Eclipse Attempt (MainNet-like)\n\
             ============================================================"
        );

        let result = run_testnet_beta_p2p_topology_scenario(&cfg);

        // Verify the scenario completed
        assert!(
            result.completed_successfully,
            "Scenario should complete without panics"
        );

        // Verify heights advanced (cluster progressed)
        assert!(
            result.max_height > 0,
            "Cluster should make progress (max_height > 0)"
        );

        // Verify the victim (node 0) has limited attacker connections
        // With max_peers_per_ipv4_prefix24 = 2, victim should have at most 2
        // outbound connections to the attacker prefix
        let victim_outbound = result
            .per_node_outbound_counts
            .first()
            .copied()
            .unwrap_or(0);
        let diversity_config = cfg.diversity_config();

        eprintln!(
            "[T207.1] Results:\n\
             - Completed: {}\n\
             - Max height: {}\n\
             - Victim outbound peers: {}\n\
             - Prefix24 rejections: {}\n\
             - Diversity config max_prefix24: {}",
            result.completed_successfully,
            result.max_height,
            victim_outbound,
            result.rejected_prefix24_total,
            diversity_config.max_peers_per_ipv4_prefix24
        );

        // In Enforce mode with 8 attackers in one prefix and limit of 2,
        // we should see at least some rejections
        assert!(
            result.rejected_prefix24_total > 0 || cfg.num_attacker_nodes <= 2,
            "Should reject excess connections from attacker prefix (or attacker count <= limit)"
        );

        eprintln!("[T207.1] PASSED: Eclipse attempt limited by diversity enforcement\n");
    }

    // ========================================================================
    // Test 2: Multi-Prefix Concentration with Warn Mode
    // ========================================================================

    /// T207.2: Test that Warn mode logs violations without rejecting.
    ///
    /// Scenario:
    /// - Cluster where bootstrap is biased toward 1-2 prefixes
    /// - diversity_mode=Warn (TestNet Beta-like)
    ///
    /// Expected:
    /// - Diversity violation metrics should increment
    /// - Cluster should still progress (connections allowed)
    #[test]
    fn test_topology_multi_prefix_concentration_warn_mode() {
        let cfg = TestnetBetaP2pTopologyConfig::concentration_warn_mode();

        eprintln!(
            "\n============================================================\n\
             T207.2: Multi-Prefix Concentration (Warn Mode)\n\
             ============================================================"
        );

        let result = run_testnet_beta_p2p_topology_scenario(&cfg);

        // Verify the scenario completed
        assert!(
            result.completed_successfully,
            "Scenario should complete without panics"
        );

        // Verify heights advanced (cluster progressed despite concentration)
        assert!(
            result.max_height > 0,
            "Cluster should make progress even with concentrated prefixes"
        );

        // Verify nodes have outbound peers (connections weren't rejected)
        let total_outbound: u16 = result.per_node_outbound_counts.iter().sum();
        assert!(
            total_outbound > 0,
            "Nodes should have outbound connections in Warn mode"
        );

        eprintln!(
            "[T207.2] Results:\n\
             - Completed: {}\n\
             - Max height: {}\n\
             - Total outbound connections: {}\n\
             - Diversity violations (warn): {}",
            result.completed_successfully,
            result.max_height,
            total_outbound,
            result.diversity_violations_total
        );

        // In Warn mode with concentrated prefixes, we may or may not see violations
        // depending on whether the concentration exceeds the warn thresholds.
        // The key assertion is that the cluster progresses.

        eprintln!("[T207.2] PASSED: Cluster progresses with concentrated prefixes in Warn mode\n");
    }

    // ========================================================================
    // Test 3: Network Partition and Heal
    // ========================================================================

    /// T207.3: Test network partition resilience and healing.
    ///
    /// Scenario:
    /// - Two disconnected partitions with separate bootstrap sets
    /// - After some time, merge bootstrap sets and enable discovery
    ///
    /// Expected:
    /// - Both partitions make progress during split
    /// - After heal, heights converge (max-min within reasonable bound)
    /// - No node ends up exclusively in one bucket (Enforce mode)
    #[test]
    fn test_topology_partition_and_heal_progress() {
        let cfg = TestnetBetaP2pTopologyConfig::partition_heal();

        eprintln!(
            "\n============================================================\n\
             T207.3: Network Partition and Heal\n\
             ============================================================"
        );

        let result = run_testnet_beta_p2p_topology_scenario(&cfg);

        // Verify the scenario completed
        assert!(
            result.completed_successfully,
            "Scenario should complete without panics"
        );

        // Verify heights advanced
        assert!(result.max_height > 0, "Cluster should make progress");

        // After healing, height spread should be small (convergence)
        let height_spread = result.max_height - result.min_height;

        eprintln!(
            "[T207.3] Results:\n\
             - Completed: {}\n\
             - Min height: {}\n\
             - Max height: {}\n\
             - Height spread after heal: {}\n\
             - Per-node distinct buckets: {:?}",
            result.completed_successfully,
            result.min_height,
            result.max_height,
            height_spread,
            result.per_node_distinct_buckets
        );

        // After healing, heights should have converged
        // Allow some spread due to simulation timing, but should be small
        assert!(
            height_spread <= 1,
            "Heights should converge after healing (spread={})",
            height_spread
        );

        // Verify nodes have connections to both partitions (diversity)
        // Check that nodes have at least 2 distinct buckets after healing
        for (i, &buckets) in result.per_node_distinct_buckets.iter().enumerate() {
            eprintln!("  Node {}: {} distinct buckets", i, buckets);
        }

        eprintln!("[T207.3] PASSED: Partitions heal and heights converge\n");
    }

    // ========================================================================
    // Unit Tests for Helper Types
    // ========================================================================

    #[test]
    fn test_topology_scenario_display() {
        assert_eq!(
            format!("{}", P2pTopologyScenario::SinglePrefixEclipseAttempt),
            "single-prefix-eclipse"
        );
        assert_eq!(
            format!("{}", P2pTopologyScenario::MultiPrefixConcentration),
            "multi-prefix-concentration"
        );
        assert_eq!(
            format!("{}", P2pTopologyScenario::NetworkSplitAndHeal),
            "partition-and-heal"
        );
    }

    #[test]
    fn test_topology_config_defaults() {
        let cfg = TestnetBetaP2pTopologyConfig::default();
        assert_eq!(cfg.num_validators, 4);
        assert_eq!(
            cfg.scenario,
            P2pTopologyScenario::SinglePrefixEclipseAttempt
        );
        assert!(!cfg.use_strict_mainnet_like_diversity);
    }

    #[test]
    fn test_topology_config_presets() {
        let eclipse = TestnetBetaP2pTopologyConfig::eclipse_mainnet_like();
        assert!(eclipse.use_strict_mainnet_like_diversity);
        assert_eq!(
            eclipse.scenario,
            P2pTopologyScenario::SinglePrefixEclipseAttempt
        );

        let concentration = TestnetBetaP2pTopologyConfig::concentration_warn_mode();
        assert!(!concentration.use_strict_mainnet_like_diversity);
        assert_eq!(
            concentration.scenario,
            P2pTopologyScenario::MultiPrefixConcentration
        );

        let partition = TestnetBetaP2pTopologyConfig::partition_heal();
        assert!(partition.use_strict_mainnet_like_diversity);
        assert_eq!(partition.scenario, P2pTopologyScenario::NetworkSplitAndHeal);
    }

    #[test]
    fn test_prefix_assignment_eclipse() {
        let assignment = TestPrefixAssignment::eclipse_scenario(4, 6);

        // Victim should be at 10.0.0.1
        let victim_ip = assignment.get_ip(0).unwrap();
        assert_eq!(victim_ip, IpAddr::V4(Ipv4Addr::new(10, 0, 0, 1)));
        assert_eq!(assignment.get_role(0), Some(NodeRole::Victim));

        // Honest nodes should be in different prefixes
        let honest1 = assignment.get_ip(1).unwrap();
        let honest2 = assignment.get_ip(2).unwrap();
        assert_ne!(
            DiversityClassifier::classify(&honest1),
            DiversityClassifier::classify(&honest2)
        );

        // Attackers should all be in the same prefix
        let attacker1 = assignment.get_ip(5).unwrap();
        let attacker2 = assignment.get_ip(6).unwrap();
        assert_eq!(
            DiversityClassifier::classify(&attacker1),
            DiversityClassifier::classify(&attacker2)
        );
        assert_eq!(assignment.get_role(5), Some(NodeRole::Attacker));
    }

    #[test]
    fn test_prefix_assignment_concentration() {
        let assignment = TestPrefixAssignment::concentration_scenario(8);

        // Most nodes should be in the concentrated prefix (10.0.1.0/24)
        let mut concentrated_count = 0;
        for i in 0..8 {
            if let Some(IpAddr::V4(ipv4)) = assignment.get_ip(i) {
                if ipv4.octets()[2] == 1 {
                    concentrated_count += 1;
                }
            }
        }

        // 75% of 8 = 6 nodes should be in concentrated prefix
        assert!(concentrated_count >= 6, "Most nodes should be concentrated");
    }

    #[test]
    fn test_prefix_assignment_partition() {
        let assignment = TestPrefixAssignment::partition_scenario(8);

        // First half should be in partition A (10.1.x.x)
        for i in 0..4 {
            assert_eq!(assignment.get_role(i), Some(NodeRole::PartitionA));
            if let Some(IpAddr::V4(ip)) = assignment.get_ip(i) {
                assert_eq!(ip.octets()[1], 1);
            }
        }

        // Second half should be in partition B (10.2.x.x)
        for i in 4..8 {
            assert_eq!(assignment.get_role(i), Some(NodeRole::PartitionB));
            if let Some(IpAddr::V4(ip)) = assignment.get_ip(i) {
                assert_eq!(ip.octets()[1], 2);
            }
        }
    }

    #[test]
    fn test_simulated_node_basic() {
        let ip = IpAddr::V4(Ipv4Addr::new(10, 0, 1, 1));
        let mut node = SimulatedNode::new(0, ip, NodeRole::Honest);

        assert_eq!(node.outbound_count(), 0);
        assert_eq!(node.height, 0);

        node.advance_height();
        assert_eq!(node.height, 1);
    }

    #[test]
    fn test_simulated_node_connection() {
        let ip1 = IpAddr::V4(Ipv4Addr::new(10, 0, 1, 1));
        let ip2 = IpAddr::V4(Ipv4Addr::new(10, 0, 2, 1));
        let mut node = SimulatedNode::new(0, ip1, NodeRole::Honest);

        let config = DiversityConfig::mainnet();

        // Should be able to connect to different prefix
        let connected = node.try_connect_outbound(&ip2, 1, &config);
        assert!(connected);
        assert_eq!(node.outbound_count(), 1);
    }
}